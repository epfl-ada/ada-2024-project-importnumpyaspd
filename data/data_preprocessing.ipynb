{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c35940-0471-47ca-b1ba-690c0d8f5335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pierr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from T_data_loader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f8231-996b-44be-a0a5-3edf522c85bb",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34212a1c-6acd-4bef-9252-ee1c9b906a96",
   "metadata": {},
   "source": [
    "This notebook aims to explain the preprocessing steps in order to get the datasets that will be used for the analysis, repectively \"Actor.pkl\" and \"Movie.pkl\" <br> All these steps are indicative, you don't have to run all these cells as running all the notebook a quite time-consuming (around 7 hours due to the part \"Data from Web\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8ec3d-fe0a-4b91-90a5-c6b09992892f",
   "metadata": {},
   "source": [
    "## IMDb datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec45fe5-7679-4471-9e06-2a1f5767eac1",
   "metadata": {},
   "source": [
    "First, you can go to https://datasets.imdbws.com, download the files and extract them :\n",
    "- title.basics.tsv.gz\n",
    "- title.crew.tsv.gz\n",
    "- title.ratings.tsv.gz\n",
    "- name.basics.tsv.gz\n",
    "  \n",
    "<br> Note that a descriptive of this dataset can be found on https://developer.imdb.com/non-commercial-datasets/ or in the README in https://github.com/epfl-ada/ada-2024-project-importnumpyaspd/tree/main/data/IMDb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5029194e-97d3-4be3-9471-c9f0c062ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the path of the folder you have just downloaded\n",
    "# the folder containing all datasets on your machine :\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5f375-f4ea-452b-85eb-8f7fd5b84a9a",
   "metadata": {},
   "source": [
    "Custom column names are defined :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1163a18-8537-46d3-9031-6e4cf1f1f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES_CREW = ['IMDb_title_ID','IMDb_director_ID', 'IMDb_writers_ID']\n",
    "NAMES_ratings = ['IMDb_title_ID', 'Average rating', 'number of votes'] \n",
    "NAMES_BASICS = ['IMDb_people_ID', 'Name', 'birthYear', 'deathYear', 'profession', 'knownForTitles']\n",
    "NAMES_TITLES = ['IMDb_title_ID', 'TitleType', 'Primary_title', 'Original_title', 'isAdult', 'release_date', 'end_year', 'runtime', 'genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a24d5-2398-4cbc-8134-88f5a51697b9",
   "metadata": {},
   "source": [
    "All datasets are loaded :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b82ede-362e-4e45-beeb-10b0790bea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IMDb_crew = pd.read_csv(path+\"title.crew.tsv/title.crew.tsv\", sep='\\t', names = NAMES_CREW, header = 0)\n",
    "df_IMDb_ratings = pd.read_csv(path+\"title.ratings.tsv/title.ratings.tsv\", sep='\\t', names = NAMES_ratings, header = 0)\n",
    "df_IMDb_title = pd.read_csv(path+\"title.basics.tsv/title.basics.tsv\", sep='\\t', names = NAMES_TITLES, header = 0, low_memory=False)\n",
    "df_IMDb_name = pd.read_csv(path+\"name.basics.tsv/name.basics.tsv\", sep='\\t', names = NAMES_BASICS, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960f395-8efd-427f-9f37-22c696a23df1",
   "metadata": {},
   "source": [
    "For title dataset, only movie must be selected (drop series,...). Without this set, df_IMDb_title is huge.\n",
    "<br> Few unecessary columns are also dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dee27ca-0979-469d-986d-3957453816cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_type = 'movie'\n",
    "df_IMDb_title = df_IMDb_title.query('TitleType==@selected_type')\n",
    "df_IMDb_title=df_IMDb_title[['IMDb_title_ID', 'release_date','runtime','Primary_title', 'Original_title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984dfdb-6bf8-40ea-827d-007fefeb8c2f",
   "metadata": {},
   "source": [
    "### Merging Titles, crews and ratings :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c0683e-902d-4249-8799-30dea5a7325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696953, 5)\n",
      "(1497560, 3)\n",
      "(10561467, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_IMDb_title.shape)\n",
    "print(df_IMDb_ratings.shape)\n",
    "print(df_IMDb_crew.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c24a49-a482-44ff-b0c2-c3d7719ac922",
   "metadata": {},
   "source": [
    "The ratings and crew dataset contains also ratings of non-movie type. We merge on title datset as we have already selected the movie's row. (here, how = left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bc0958-77a5-4ca4-9fc9-ddaffc003508",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDb_title_rating = pd.merge(df_IMDb_title, df_IMDb_ratings, how='left', on = 'IMDb_title_ID' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de7186c-3c86-45e0-b8aa-7a0c2800761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDb = pd.merge(IMDb_title_rating, df_IMDb_crew, how='left', on = 'IMDb_title_ID' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe1961-f1dd-492f-89b6-012948cf5f66",
   "metadata": {},
   "source": [
    "## CMU \"Per title\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb231a69-7e92-414b-91e0-0a385283066c",
   "metadata": {},
   "source": [
    "You can go to https://www.cs.cmu.edu/~ark/personas/, download the dataset and extract all files. This webpage provide also a descriptive of the datasets. A more detailed description figures in the README of the download folder or in https://github.com/epfl-ada/ada-2024-project-importnumpyaspd/tree/main/data/CMU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab0d34-973d-4a64-b9d9-06847e22de11",
   "metadata": {},
   "source": [
    "We are interested in the movie.metadata file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c00601-84b0-4c04-bba2-21085573672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom column names :\n",
    "NAMES_MOVIES = ['Wikipedia_movie_ID','Freebase_movie_ID','Movie_name','Movie_release_date','Movie_box_office_revenue','Movie_runtime','Movie_languages','Movie_countries','Movie_genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2247d48-fe66-4090-beb5-9d775192cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df_CMU_movies = pd.read_csv(path+\"MovieSummaries/movie.metadata.tsv\", sep='\\t', names = NAMES_MOVIES, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c2df9b-2033-43ba-994a-5005ae8b0403",
   "metadata": {},
   "source": [
    "## Merging CMU \"Per title\" and IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f4b09-c009-4ca0-997f-ea12d0dd9b40",
   "metadata": {},
   "source": [
    "### Using unique index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f507e-b7f0-452e-805d-b1f7d51b22e9",
   "metadata": {},
   "source": [
    "We will try to merge both datsets using a unique index. Few combination of columns have been tried to achieve a satisfying result. Here we show our final choice that where the new index is composed of the name and the release year of the movies. So we supposed that these 2 informations were necessary to distinguish between every movies. As we will see in the following cells it was somethimes not sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18788b06-8145-4199-b7f5-689176460028",
   "metadata": {},
   "source": [
    "We keep only the year as release date : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9db008c-74c4-4e04-842c-2bd3a22a83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CMU\n",
    "df_CMU_movies[\"Movie_release_date\"]=pd.to_datetime(df_CMU_movies[\"Movie_release_date\"], format='mixed', errors='coerce').dt.year.astype('Int64')\n",
    "# For IMDb\n",
    "IMDb['release_date']=pd.to_datetime(IMDb['release_date'], format='mixed', errors='coerce').dt.year.astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc599a3-720a-44b6-a36d-a6defc3f3a0e",
   "metadata": {},
   "source": [
    "A new column \"modified name\" is created where we drop the ponctuation and the space. All characters are also in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f900ca60-7369-4a46-ba78-b554e32d717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CMU\n",
    "df_CMU_movies_modified_title = df_CMU_movies.Movie_name.str.replace(r'[^\\w\\s]', '', regex=True).str.replace(r'\\s+', '', regex=True).str.lower()\n",
    "df_CMU_movies[\"modified_title\"]=df_CMU_movies_modified_title\n",
    "# For IMDb\n",
    "df_IMDb_modified_title = IMDb.Primary_title.str.replace(r'[^\\w\\s]', '', regex=True).str.replace(r'\\s+', '', regex=True).str.lower()\n",
    "IMDb[\"modified_title\"]=df_IMDb_modified_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be166525-8251-47ce-ab95-3a2cd55dd36f",
   "metadata": {},
   "source": [
    "(copy for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "426816a4-e39a-4c22-ae6d-0a4af590868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_IMDb_copy = IMDb.copy()\n",
    "init_CMU_copy = df_CMU_movies.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea22836-a056-4101-8e1f-95e831de173c",
   "metadata": {},
   "source": [
    "All rows with NAN in Title name / date are dropped :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45c1f679-624c-463b-b616-8bba64ad44ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6903 rows are lost with this operation in CMU dataset.  / 81740 \n",
      "101376 rows are lost with this operation in IMDb dataset. / 696953\n"
     ]
    }
   ],
   "source": [
    "# For CMU\n",
    "s1 = df_CMU_movies.shape[0]\n",
    "df_CMU_movies = df_CMU_movies.dropna(subset=['Movie_release_date'])\n",
    "s2 = df_CMU_movies.shape[0]\n",
    "print(f'{s1-s2} rows are lost with this operation in CMU dataset.  / {s1} ')\n",
    "# For IMDb\n",
    "s1 = IMDb.shape[0]\n",
    "IMDb = IMDb.dropna(subset=['release_date'])\n",
    "s2 = IMDb.shape[0]\n",
    "print(f'{s1-s2} rows are lost with this operation in IMDb dataset. / {s1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "772ccdf8-2e79-455b-88fc-86ea0ce7b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check of the size of the CMU containing the NAN values : 6903\n"
     ]
    }
   ],
   "source": [
    "# Store a dataset with row with NAN as Title or release date\n",
    "# This step is done in prevision of the section \"Merging using Data from the web\".\n",
    "CMU_with_NAN = init_CMU_copy[~init_CMU_copy.index.isin(df_CMU_movies.index)]\n",
    "print(f'Quick check of the size of the CMU containing the NAN values : {CMU_with_NAN.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4203e8f9-ae42-4e5f-bb7f-94a4b94f4037",
   "metadata": {},
   "source": [
    "Defining new index names based on release date and title : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd9e8181-f5e8-4eee-a287-d16826b01953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CMU\n",
    "new_id_CMU = df_CMU_movies.Movie_release_date.astype(str)+df_CMU_movies.modified_title\n",
    "# For IMDb\n",
    "new_id_IMDb = IMDb.release_date.astype(str)+IMDb.modified_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5baaf-e746-4b62-ab61-8b1dc5acf471",
   "metadata": {},
   "source": [
    "Once we get the new index, we check that this is a unique index :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9d7b52a-aba3-4915-b96f-bdde05a1ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMU has a unique indexing : False\n",
      "IMDb has a unique indexing : False\n"
     ]
    }
   ],
   "source": [
    "# For CMU\n",
    "CMU_movies_newind = df_CMU_movies.copy()\n",
    "CMU_movies_newind.index = new_id_CMU\n",
    "print(f'CMU has a unique indexing : {CMU_movies_newind.index.is_unique}')\n",
    "# For IMDb\n",
    "IMDb_movies_newind = IMDb.copy()\n",
    "IMDb_movies_newind.index = new_id_IMDb\n",
    "print(f'IMDb has a unique indexing : {IMDb_movies_newind.index.is_unique}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25090a-7a41-4c89-9ca8-e585d2836159",
   "metadata": {},
   "source": [
    "Unfortunately we have a non unique indexing.<br>Let's count how much rows have the same index :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d22bb518-88c7-4104-9484-1a669e4012b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 rows are lost with this operation in CMU dataset  / 74837 \n",
      "CMU has a unique indexing : True\n"
     ]
    }
   ],
   "source": [
    "mask_duplicate = CMU_movies_newind.index.duplicated(keep=False)\n",
    "df_CMU_movies_wo_dupl = CMU_movies_newind[~mask_duplicate]\n",
    "\n",
    "s1 = CMU_movies_newind.shape[0]\n",
    "s2 = df_CMU_movies_wo_dupl.shape[0]\n",
    "\n",
    "print(f'{s1-s2} rows are lost with this operation in CMU dataset  / {s1} ')\n",
    "print(f'CMU has a unique indexing : {df_CMU_movies_wo_dupl.index.is_unique}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d5cf5c-fbfa-4c50-a5ba-c13677531b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11132 rows are lost with this operation in IMDb dataset / 595577\n",
      "IMDb has a unique indexing : True\n"
     ]
    }
   ],
   "source": [
    "mask_duplicate = IMDb_movies_newind.index.duplicated(keep=False)\n",
    "df_IMDb_movies_wo_dupl = IMDb_movies_newind[~mask_duplicate]\n",
    "\n",
    "s1 = IMDb_movies_newind.shape[0]\n",
    "s2 = df_IMDb_movies_wo_dupl.shape[0]\n",
    "\n",
    "print(f'{s1-s2} rows are lost with this operation in IMDb dataset / {s1}')\n",
    "print(f'IMDb has a unique indexing : {df_IMDb_movies_wo_dupl.index.is_unique}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c738572-94a9-4827-bb36-03306b32124d",
   "metadata": {},
   "source": [
    "As the amount of duplicates are small, we decide to drop all of them for this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c5f53-12e9-4d44-8ce2-81cfc9bf0364",
   "metadata": {},
   "source": [
    "#### Merge CMU with IMDb :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e92e3882-e5c5-4fab-9eba-eca58988d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df_IMDb_movies_wo_dupl.merge(df_CMU_movies_wo_dupl, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf6df670-d15c-4f01-92a4-15e9424e3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 44864 out of 81740 have a match\n"
     ]
    }
   ],
   "source": [
    "print(f'A total of {merged.shape[0]} out of {init_CMU_copy.shape[0]} have a match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab8b55-d6c8-4987-86aa-add60819677b",
   "metadata": {},
   "source": [
    "Previously we used the \"primary title\" of the IMDb dataset to create the \"modified_title\" columns. Let's redo the previous operation on the \"original title\" column of the IMDb dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1fdda-79f0-45d8-ae1d-9945f711e5cd",
   "metadata": {},
   "source": [
    "We don't start with the entire dataset, but we take the unmatched rows of each dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a47a9017-965a-4cc4-a84f-c6107aa6064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549793, 10)\n",
      "(29698, 10)\n"
     ]
    }
   ],
   "source": [
    "notmatched_CMU = df_CMU_movies_wo_dupl[~df_CMU_movies_wo_dupl.index.isin(df_IMDb_movies_wo_dupl.index)]\n",
    "notmatched_IMDb = IMDb_movies_newind[~IMDb_movies_newind.index.isin(df_CMU_movies_wo_dupl.index)]\n",
    "\n",
    "print(notmatched_IMDb.shape)\n",
    "print(notmatched_CMU.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793bfce4-4159-42d9-85a2-87de5488ff30",
   "metadata": {},
   "source": [
    "(Same procedure as before but with Original_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ec271f7-25be-46b4-bc0a-4bf8c0b43561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11132 rows are lost with this operation in IMDb dataset / 595577\n",
      "IMDb has a unique indexing : True\n"
     ]
    }
   ],
   "source": [
    "notmatched_IMDb = notmatched_IMDb.drop(columns=[\"modified_title\"])\n",
    "df_IMDb_modified_titlev2 = notmatched_IMDb.Original_title.str.replace(r'[^\\w\\s]', '', regex=True).str.replace(r'\\s+', '', regex=True).str.lower()\n",
    "notmatched_IMDb[\"modified_title\"]=df_IMDb_modified_titlev2\n",
    "new_id_IMDbv2 = notmatched_IMDb.release_date.astype(str)+notmatched_IMDb.modified_title\n",
    "\n",
    "notmatched_IMDb_newind = notmatched_IMDb.copy()\n",
    "notmatched_IMDb_newind.index = new_id_IMDbv2\n",
    "\n",
    "mask_duplicate = notmatched_IMDb_newind.index.duplicated(keep=False)\n",
    "notmatched_IMDb_wo_dupl = notmatched_IMDb_newind[~mask_duplicate]\n",
    "\n",
    "print(f'{s1-s2} rows are lost with this operation in IMDb dataset / {s1}')\n",
    "print(f'IMDb has a unique indexing : {notmatched_IMDb_wo_dupl.index.is_unique}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f110e-179b-42dd-be50-d35ba021f2db",
   "metadata": {},
   "source": [
    "We merge the 2 datasets of unmatched rows (that also have unique index) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e5a0143-cd50-44ec-a3b1-aaf8a97bbb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We add 3115 rows using the original title !\n"
     ]
    }
   ],
   "source": [
    "mergedv2 = notmatched_IMDb_wo_dupl.merge(notmatched_CMU, left_index=True, right_index=True, how='inner')\n",
    "print(f'We add {mergedv2.shape[0]} rows using the original title !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f2806-97e4-44a1-a184-97640396e7ba",
   "metadata": {},
   "source": [
    "We then concat both merge :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ddacbb8-05e2-4671-85d6-c81fe8d8c975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge dataset has unique indexing : True\n",
      "Size of dataset : (47979, 20)\n"
     ]
    }
   ],
   "source": [
    "merge_final = pd.concat([merged,mergedv2])\n",
    "print(f'Merge dataset has unique indexing : {merge_final.index.is_unique}')\n",
    "print(f'Size of dataset : {merge_final.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759971de-fe3e-41b8-b31f-b9992a74a77a",
   "metadata": {},
   "source": [
    "As se can see, a non negligeble part of CMU dataset has not find a match : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de5287c9-218e-41b4-a155-38d5aee1207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26583\n",
      "6903\n",
      "33486\n",
      "Number of unmatched rows of CMU dataset : (33486, 10)\n"
     ]
    }
   ],
   "source": [
    "#CMU\n",
    "notmatched_CMU2 = notmatched_CMU[~notmatched_CMU.index.isin(notmatched_IMDb_wo_dupl.index)]\n",
    "## add also the part of CMU that was dropped since they have a NAN in column \"title or release date\"\n",
    "notmatched_CMU2 = pd.concat([CMU_with_NAN,notmatched_CMU2])\n",
    "#IMDb\n",
    "notmatched_IMDb2 = notmatched_IMDb_wo_dupl[~notmatched_IMDb_wo_dupl.index.isin(notmatched_CMU.index)]\n",
    "\n",
    "print(f'Number of unmatched rows of CMU dataset : {notmatched_CMU2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba570b76-f32e-4261-971a-66d463ede0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "      <th>modified_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11250635</td>\n",
       "      <td>/m/02r52hc</td>\n",
       "      <td>The Mechanical Monsters</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/03k9fj\": \"...</td>\n",
       "      <td>themechanicalmonsters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>31137877</td>\n",
       "      <td>/m/0gh7n22</td>\n",
       "      <td>Boadicea</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\", \"/m/03hn0\": \"Historica...</td>\n",
       "      <td>boadicea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>27374355</td>\n",
       "      <td>/m/0by1_ff</td>\n",
       "      <td>Les Indiens sont encore loin</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"/m/0f8l9c\": \"France\", \"/m/06mzp\": \"Switzerla...</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "      <td>lesindienssontencoreloin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>29766415</td>\n",
       "      <td>/m/0fp_syp</td>\n",
       "      <td>Donald's Crime</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"/m/02hmvc\": \"Short Film\"}</td>\n",
       "      <td>donaldscrime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>28415406</td>\n",
       "      <td>/m/0crj1f3</td>\n",
       "      <td>The Last Trackers of the Outback</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/0f8l9c\": \"France\", \"/m/0chghy\": \"Australia\"}</td>\n",
       "      <td>{\"/m/0jtdp\": \"Documentary\"}</td>\n",
       "      <td>thelasttrackersoftheoutback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wikipedia_movie_ID Freebase_movie_ID                        Movie_name  \\\n",
       "14             11250635        /m/02r52hc           The Mechanical Monsters   \n",
       "73             31137877        /m/0gh7n22                          Boadicea   \n",
       "80             27374355        /m/0by1_ff      Les Indiens sont encore loin   \n",
       "102            29766415        /m/0fp_syp                    Donald's Crime   \n",
       "119            28415406        /m/0crj1f3  The Last Trackers of the Outback   \n",
       "\n",
       "     Movie_release_date  Movie_box_office_revenue  Movie_runtime  \\\n",
       "14                 <NA>                       NaN            NaN   \n",
       "73                 <NA>                       NaN            NaN   \n",
       "80                 <NA>                       NaN           95.0   \n",
       "102                <NA>                       NaN            NaN   \n",
       "119                <NA>                       NaN            NaN   \n",
       "\n",
       "                        Movie_languages  \\\n",
       "14   {\"/m/02h40lc\": \"English Language\"}   \n",
       "73                                   {}   \n",
       "80                                   {}   \n",
       "102                                  {}   \n",
       "119  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                                       Movie_countries  \\\n",
       "14           {\"/m/09c7w0\": \"United States of America\"}   \n",
       "73                                                  {}   \n",
       "80   {\"/m/0f8l9c\": \"France\", \"/m/06mzp\": \"Switzerla...   \n",
       "102                                                 {}   \n",
       "119  {\"/m/0f8l9c\": \"France\", \"/m/0chghy\": \"Australia\"}   \n",
       "\n",
       "                                          Movie_genres  \\\n",
       "14   {\"/m/06n90\": \"Science Fiction\", \"/m/03k9fj\": \"...   \n",
       "73   {\"/m/07s9rl0\": \"Drama\", \"/m/03hn0\": \"Historica...   \n",
       "80                             {\"/m/07s9rl0\": \"Drama\"}   \n",
       "102                        {\"/m/02hmvc\": \"Short Film\"}   \n",
       "119                        {\"/m/0jtdp\": \"Documentary\"}   \n",
       "\n",
       "                  modified_title  \n",
       "14         themechanicalmonsters  \n",
       "73                      boadicea  \n",
       "80      lesindienssontencoreloin  \n",
       "102                 donaldscrime  \n",
       "119  thelasttrackersoftheoutback  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notmatched_CMU2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c37f5f-e562-4bab-b755-92494e15c97a",
   "metadata": {},
   "source": [
    "Next section will try a other way to merge these 2 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f542950d-e94a-423d-978d-6d2391f4a174",
   "metadata": {},
   "source": [
    "As the amount of duplicates respectively to their index (release year + name) are almost negligible, we don't take care of adding them in the \"notmatched_CMU2\" and \"notmatched_IMDb2\" for the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441dd57e-37a0-4ed1-9820-e66097e2e5fa",
   "metadata": {},
   "source": [
    "### Merging using Data from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631bfc0-aa48-4832-b03f-afee596dcc07",
   "metadata": {},
   "source": [
    "We try now to get the IMDb id of the movie contained in CMU dataset by scraping wikipedia. This method seems to be really precise to merge both dataset, but it was not consider in the first step due to it's computational time. Now that we've reduced the number of samples, let's see what we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98619833-8dce-48e9-9477-2c6d06e63aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.parse as url\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24d6a2-e93b-4387-9f5d-07e964ccbdca",
   "metadata": {},
   "source": [
    "The function \"get_IMDb_id\" do :\n",
    "- go to wikipedia page of the film using the wikipedia id\n",
    "- search in the HTML text for an URL that starts with \"https://www.imdb.com/title/tt\". (This is the imbd URL of the film)\n",
    "- if there is a single adresse looking like this in the HTML page it return last part of the URL (\"A part of path\") that correspond to the IMDb id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b58e7154-0b4d-4406-9a18-f127f4cdf0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IMDb_id(wikipedia_id):\n",
    "    # sources : \n",
    "    # - https://www.geeksforgeeks.org/beautifulsoup-scraping-link-from-html/\n",
    "    # - https://stackoverflow.com/questions/7253803/how-to-get-everything-after-last-slash-in-a-url\n",
    "    r = requests.get(\"https://en.wikipedia.org/?curid=\"+str(wikipedia_id))\n",
    "    \n",
    "    if r.status_code == 404:\n",
    "        return pd.NA\n",
    "        \n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    nbr_link = 0\n",
    "    for link in soup.find_all('a',attrs={'href': re.compile(\"^https://www.imdb.com/title/tt\")}):\n",
    "        nbr_link += 1\n",
    "        href  = link.get('href')\n",
    "        url_parts = url.urlparse(href)\n",
    "        IMBd_id = url_parts.path.split('/')[2]\n",
    "    if nbr_link==1:\n",
    "        return IMBd_id\n",
    "    else :\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e45c6ccb-ed6c-47f8-8fd5-77d97fc36775",
   "metadata": {},
   "outputs": [],
   "source": [
    "notmatched_CMU2_copy = notmatched_CMU2.copy()\n",
    "notmatched_CMU2_copy=notmatched_CMU2_copy['Wikipedia_movie_ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df7b56d2-81c6-4196-9328-2a43dcb9f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26583/26583 [6:40:28<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "notmatched_CMU2_copy = notmatched_CMU2_copy.progress_apply(lambda x: get_IMDb_id(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad2326-bd0c-48ed-9db2-8e83d963b72d",
   "metadata": {},
   "source": [
    "Finally we can merge the notmatched dataset and concat it with the merge_dataset that we got using unique indexing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5da9b056-124a-4758-8212-512d3da28b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/w8_bl_xd53n7dlt9q3m5v8vm0000gn/T/ipykernel_27614/483739325.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  notmatched_CMU2['IMDb_title_ID'] = notmatched_CMU2_copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9753 new samples have been matched with web scraping !\n",
      "Final score :\n",
      "57732 out of 81740 have been matched\n"
     ]
    }
   ],
   "source": [
    "notmatched_CMU2['IMDb_title_ID'] = notmatched_CMU2_copy\n",
    "mergev3 = pd.merge(notmatched_IMDb2, notmatched_CMU2, how = 'inner', on = 'IMDb_title_ID' )\n",
    "print(f'{mergev3.shape[0]} new samples have been matched with web scraping !')\n",
    "final = pd.concat([merge_final,mergev3])\n",
    "print(\"Final score :\")\n",
    "print(f'{final.shape[0]} out of {init_CMU_copy.shape[0]} have been matched')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c910ad7-886e-4a14-a650-b365c2011c1c",
   "metadata": {},
   "source": [
    "## CMU actor dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a75e12-3bed-4701-8801-7de312138e88",
   "metadata": {},
   "source": [
    "Reminder <br>\n",
    "You can go to https://www.cs.cmu.edu/~ark/personas/, download the dataset and extract all files. This webpage provide also a descriptive of the datasets. A more detailed description figures in the README of the download folder or in https://github.com/epfl-ada/ada-2024-project-importnumpyaspd/tree/main/data/CMU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6605d-1869-4216-a9ec-88afa069caa6",
   "metadata": {},
   "source": [
    "We are interested now in the character.metadata file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79a431f8-bb1e-4684-8166-3e7a7359c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom column names :\n",
    "character_column = ['Wikipedia_movie_ID','Freebase_movie_ID','Movie_release_date','Character_name','actor_DOB','actor_gender','actor_height','actor_ethnicity','actor_name','actor_age_atmovierelease','freebase_character_actor_map_id','freebase_character_id','freebase_actor_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d85c20c8-c654-4ebe-9f35-49fc481deed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "CMU_character = pd.read_csv(path+\"/MovieSummaries/character.metadata.tsv\", sep='\\t',names = character_column, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed32a2c-27a5-4ef2-92ca-e36bb5c1bfb9",
   "metadata": {},
   "source": [
    "We are interested to get a serie that have in index the name of an actor and contain a list of all the film that he plays in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c830a28-cf20-402c-8304-e546e647ba11",
   "metadata": {},
   "source": [
    "We have done it using groupby and apply methods : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e64194a-028b-41d8-a1d7-ca3488671c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_films(df):\n",
    "    list_film = df.Freebase_movie_ID.tolist()\n",
    "    return list_film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db70d65f-3c32-4667-8488-92e9716a806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = CMU_character.groupby(by='freebase_actor_id').apply(get_films,include_groups=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f75c0-a037-49e8-92b7-0a0eabbb7946",
   "metadata": {},
   "source": [
    "## Save final dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363eab40-a163-414a-ac8a-4b9dfb2a3474",
   "metadata": {},
   "source": [
    "All dataset are ready to be used for the analysis. Let's save them in pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdd8c830-a162-400c-8f9a-75a9769cadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/alexandre/Desktop/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec2f1d5a-778c-4c4e-bed0-f525e7869691",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.to_pickle(path+'/Actor.pkl')\n",
    "final.to_pickle(path+'/Movie.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585496c3-2ae4-4286-9b00-f34bef69a282",
   "metadata": {},
   "source": [
    "## Ethnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed3f552-d9fc-496d-a87d-183145207ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_path = 'Character.pkl'\n",
    "with open(characters_path, 'rb') as file:\n",
    "    Characters = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d225c4d0-bdcf-40a9-8408-bb331280b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7edd9c12-16c8-4035-98f4-de0693959678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ethnie(wikipedia_id):\n",
    "\n",
    "    r = requests.get(\"https://www.wikidata.org/wiki/Special:Search\"+wikipedia_id)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    etnies = soup.find('a', href=True, attrs={'data-serp-pos': '0', 'title': True})\n",
    "    if etnies is not None:\n",
    "        abc = etnies.find('span', class_='wb-itemlink-label').text\n",
    "    else :\n",
    "        abc = 0\n",
    "    return abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee74d6f0-bd64-4a3d-a889-923ec5cfd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnie_id = pd.unique(Characters['Actor_ethnicity'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70a722f-3a12-427e-9392-0cdbbeb8a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnie = pd.Series(\"ethnie\", index = ethnie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8daa63f6-36a9-4fc0-bc78-d6b7872d4e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [11:17<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in tqdm(ethnie_id):\n",
    "    ethnie.iloc[a] = get_ethnie(i)\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f7b998c-c613-4ddd-a71d-0e3708e2fbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnie[ethnie == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edd524c1-aeb8-4eed-be72-8cdb4b151a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnie.to_pickle('ethnie.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270ae0f-f27e-4b0d-8dbb-b991b70b79c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
